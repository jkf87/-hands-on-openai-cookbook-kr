{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a06ec76c",
   "metadata": {},
   "source": [
    "# 채팅 모델 미세 조정을 위한 데이터 준비 및 분석\n",
    "\n",
    "이 노트북은 채팅 모델 미세 조정에 사용되는 채팅 데이터 세트를 전처리하고 분석하는 도구로 사용됩니다.\n",
    "형식 오류를 확인하고, 기본 통계를 제공하며, 미세 조정 비용을 위한 토큰 수를 추정합니다.\n",
    "여기에 표시된 방법은 gpt-3.5-turbo의 [현재 미세 조정 방법](https://platform.openai.com/docs/guides/fine-tuning)에 해당합니다.\n",
    "babbage-002 및 davinci-002와 같은 모델의 경우 [레거시 미세 조정](https://platform.openai.com/docs/guides/legacy-fine-tuning)을 참조하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e63973b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tiktoken # for token counting\n",
    "import numpy as np\n",
    "from collections import defaultdict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "013bdbc4",
   "metadata": {},
   "source": [
    "데이터 로딩 중 ##\n",
    "\n",
    "먼저 [예제 JSONL 파일](https://github.com/openai/openai-cookbook/blob/main/examples/data/toy_chat_fine_tuning.jsonl)에서 채팅 데이터 세트를 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c248ccd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples: 5\n",
      "First example:\n",
      "{'role': 'system', 'content': 'You are a happy assistant that puts a positive spin on everything.'}\n",
      "{'role': 'user', 'content': 'I fell off my bike today.'}\n",
      "{'role': 'assistant', 'content': \"It's great that you're getting exercise outdoors!\"}\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/toy_chat_fine_tuning.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = [json.loads(line) for line in f]\n",
    "\n",
    "# Initial dataset stats\n",
    "print(\"Num examples:\", len(dataset))\n",
    "print(\"First example:\")\n",
    "for message in dataset[0][\"messages\"]:\n",
    "    print(message)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17903d61",
   "metadata": {},
   "source": [
    "## 형식 유효성 검사\n",
    "\n",
    "다양한 오류 검사를 수행하여 데이터 세트의 각 대화가 미세 조정 API에서 예상하는 형식을 준수하는지 검증할 수 있습니다. 오류는 그 성격에 따라 분류되어 디버깅이 더 쉬워집니다.\n",
    "\n",
    "1. **데이터 유형 검사**: 데이터 세트의 각 항목이 사전(`딕트`)인지 여부를 확인합니다. 오류 유형: `데이터_유형`.\n",
    "2. **메시지 목록 존재 여부**: 각 항목에 `메시지` 목록이 있는지 확인합니다. 오류 유형: `missing_messages_list`.\n",
    "3. **메시지 키 확인**: 메시지` 목록의 각 메시지에 `역할` 및 `내용` 키가 포함되어 있는지 확인합니다. 오류 유형: `메시지_미싱_키`.\n",
    "4. **메시지에서 인식할 수 없는 키**: 메시지에 `역할`, `내용`, `이름` 이외의 키가 있는 경우 로그를 기록합니다. 오류 유형: 메시지_미인식_키`.\n",
    "5. **역할 유효성 검사**: '역할'이 '시스템', '사용자' 또는 '어시스턴트' 중 하나인지 확인합니다. 오류 유형: '인식할 수 없는 역할'.\n",
    "6. **콘텐츠 유효성 검사**: 콘텐츠`에 텍스트 데이터가 있고 문자열인지 확인합니다. 오류 유형: `missing_content`.\n",
    "7. **어시스턴트 메시지 존재 여부**: 각 대화에 어시스턴트가 보낸 메시지가 하나 이상 있는지 확인합니다. 오류 유형: `EXAMPLE_MISSING_ASSISTANT_MESSAGE`.\n",
    "\n",
    "아래 코드는 이러한 검사를 수행하며, 발견된 각 오류 유형에 대한 개수를 출력합니다. 이는 디버깅하고 데이터 세트가 다음 단계에 사용할 준비가 되었는지 확인하는 데 유용합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9f3ccbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No errors found\n"
     ]
    }
   ],
   "source": [
    "# Format error checks\n",
    "format_errors = defaultdict(int)\n",
    "\n",
    "for ex in dataset:\n",
    "    if not isinstance(ex, dict):\n",
    "        format_errors[\"data_type\"] += 1\n",
    "        continue\n",
    "        \n",
    "    messages = ex.get(\"messages\", None)\n",
    "    if not messages:\n",
    "        format_errors[\"missing_messages_list\"] += 1\n",
    "        continue\n",
    "        \n",
    "    for message in messages:\n",
    "        if \"role\" not in message or \"content\" not in message:\n",
    "            format_errors[\"message_missing_key\"] += 1\n",
    "        \n",
    "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
    "            format_errors[\"message_unrecognized_key\"] += 1\n",
    "        \n",
    "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
    "            format_errors[\"unrecognized_role\"] += 1\n",
    "            \n",
    "        content = message.get(\"content\", None)\n",
    "        function_call = message.get(\"function_call\", None)\n",
    "        \n",
    "        if (not content and not function_call) or not isinstance(content, str):\n",
    "            format_errors[\"missing_content\"] += 1\n",
    "    \n",
    "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
    "        format_errors[\"example_missing_assistant_message\"] += 1\n",
    "\n",
    "if format_errors:\n",
    "    print(\"Found errors:\")\n",
    "    for k, v in format_errors.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "else:\n",
    "    print(\"No errors found\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "981e77da",
   "metadata": {},
   "source": [
    "토큰 카운팅 유틸리티 ##\n",
    "\n",
    "노트북의 나머지 부분에서 사용할 몇 가지 유용한 유틸리티를 정의해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f4b47b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "# not exact!\n",
    "# simplified from https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        num_tokens += tokens_per_message\n",
    "        for key, value in message.items():\n",
    "            num_tokens += len(encoding.encode(value))\n",
    "            if key == \"name\":\n",
    "                num_tokens += tokens_per_name\n",
    "    num_tokens += 3\n",
    "    return num_tokens\n",
    "\n",
    "def num_assistant_tokens_from_messages(messages):\n",
    "    num_tokens = 0\n",
    "    for message in messages:\n",
    "        if message[\"role\"] == \"assistant\":\n",
    "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
    "    return num_tokens\n",
    "\n",
    "def print_distribution(values, name):\n",
    "    print(f\"\\n#### Distribution of {name}:\")\n",
    "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
    "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
    "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0fdff67d",
   "metadata": {},
   "source": [
    "데이터 경고 및 토큰 수 ##\n",
    "\n",
    "몇 가지 가벼운 분석을 통해 누락된 메시지와 같은 데이터 세트의 잠재적인 문제를 식별하고 메시지 및 토큰 수에 대한 통계적 인사이트를 제공할 수 있습니다.\n",
    "\n",
    "1. **누락된 시스템/사용자 메시지**: '시스템' 또는 '사용자' 메시지가 누락된 대화의 수를 계산합니다. 이러한 메시지는 어시스턴트의 행동을 정의하고 대화를 시작하는 데 매우 중요합니다.\n",
    "2. **예시당 메시지 수**: 각 대화에 포함된 메시지 수의 분포를 요약하여 대화의 복잡성에 대한 통찰력을 제공합니다.\n",
    "3. **예시당 총 토큰 수**: 각 대화의 총 토큰 수 분포를 계산하고 요약합니다. 미세 조정 비용을 이해하는 데 중요합니다.\n",
    "4. **어시스턴트 메시지의 토큰 수**: 대화당 어시스턴트 메시지의 토큰 수를 계산하고 이 분포를 요약합니다. 어시스턴트의 장황함을 이해하는 데 유용합니다.\n",
    "5. **토큰 한도 경고**: 최대 토큰 한도(4096개)를 초과하는 예시가 있는지 확인합니다. 이러한 예시는 미세 조정 중에 잘려서 데이터 손실이 발생할 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52e58ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num examples missing system message: 1\n",
      "Num examples missing user message: 1\n",
      "\n",
      "#### Distribution of num_messages_per_example:\n",
      "min / max: 2, 9\n",
      "mean / median: 3.8, 3.0\n",
      "p5 / p95: 2.0, 6.6000000000000005\n",
      "\n",
      "#### Distribution of num_total_tokens_per_example:\n",
      "min / max: 26, 8032\n",
      "mean / median: 1648.4, 45.0\n",
      "p5 / p95: 26.8, 4863.6\n",
      "\n",
      "#### Distribution of num_assistant_tokens_per_example:\n",
      "min / max: 4, 8000\n",
      "mean / median: 1610.2, 10.0\n",
      "p5 / p95: 6.0, 4811.200000000001\n",
      "\n",
      "1 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
     ]
    }
   ],
   "source": [
    "# Warnings and tokens counts\n",
    "n_missing_system = 0\n",
    "n_missing_user = 0\n",
    "n_messages = []\n",
    "convo_lens = []\n",
    "assistant_message_lens = []\n",
    "\n",
    "for ex in dataset:\n",
    "    messages = ex[\"messages\"]\n",
    "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
    "        n_missing_system += 1\n",
    "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
    "        n_missing_user += 1\n",
    "    n_messages.append(len(messages))\n",
    "    convo_lens.append(num_tokens_from_messages(messages))\n",
    "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
    "    \n",
    "print(\"Num examples missing system message:\", n_missing_system)\n",
    "print(\"Num examples missing user message:\", n_missing_user)\n",
    "print_distribution(n_messages, \"num_messages_per_example\")\n",
    "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
    "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
    "n_too_long = sum(l > 4096 for l in convo_lens)\n",
    "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2afb04df",
   "metadata": {},
   "source": [
    "비용 견적 ##\n",
    "\n",
    "이 마지막 섹션에서는 미세 조정에 사용될 총 토큰 수를 추정하여 대략적인 비용을 추정할 수 있습니다. 미세 조정 작업의 기간도 토큰 수에 따라 증가한다는 점에 유의할 필요가 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb95a7ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset has ~4306 tokens that will be charged for during training\n",
      "By default, you'll train for 20 epochs on this dataset\n",
      "By default, you'll be charged for ~86120 tokens\n"
     ]
    }
   ],
   "source": [
    "# Pricing and default n_epochs estimate\n",
    "MAX_TOKENS_PER_EXAMPLE = 4096\n",
    "\n",
    "TARGET_EPOCHS = 3\n",
    "MIN_TARGET_EXAMPLES = 100\n",
    "MAX_TARGET_EXAMPLES = 25000\n",
    "MIN_DEFAULT_EPOCHS = 1\n",
    "MAX_DEFAULT_EPOCHS = 25\n",
    "\n",
    "n_epochs = TARGET_EPOCHS\n",
    "n_train_examples = len(dataset)\n",
    "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
    "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
    "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
    "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
    "\n",
    "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
    "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
    "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
    "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0ad0369",
   "metadata": {},
   "source": [
    "총 비용을 추정하려면 https://openai.com/pricing 을 참조하세요."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
