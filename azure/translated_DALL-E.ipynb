{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure DALL-E 이미지 생성 예제\n",
    "\n",
    "이 노트북은 Azure OpenAI 서비스를 사용하여 이미지를 생성하는 방법을 보여줍니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "설정 ## 설정\n",
    "\n",
    "먼저 필요한 종속성을 설치합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install openai\n",
    "# We need requests to retrieve the generated image\n",
    "! pip install requests\n",
    "# We use Pillow to display the generated image\n",
    "! pip install pillow \n",
    "# (Optional) If you want to use Microsoft Active Directory\n",
    "! pip install azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "또한, Azure OpenAI 서비스에 제대로 접속하기 위해서는 [Azure 포털](https://portal.azure.com)에서 적절한 리소스를 생성해야 합니다(자세한 방법은 [Microsoft Docs](https://learn.microsoft.com/en-us/azure/cognitive-services/openai/how-to/create-resource?pivots=web-portal)에서 확인 가능).\n",
    "\n",
    "리소스가 생성되면 가장 먼저 사용해야 하는 것은 엔드포인트입니다. 엔드포인트는 *\"리소스 관리\"* 섹션의 *\"키 및 엔드포인트\"* 섹션을 확인하면 얻을 수 있습니다. 이 정보가 있으면 이 정보를 사용하여 SDK를 설정합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_base = '' # Add your endpoint here\n",
    "\n",
    "# At the moment DALL·E is only supported by the 2023-06-01-preview API version\n",
    "openai.api_version = '2023-06-01-preview'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "인증 ### 인증\n",
    "\n",
    "Azure OpenAI 서비스는 API 키 및 Azure 자격 증명을 포함하는 여러 인증 메커니즘을 지원합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_azure_active_directory = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### API 키를 사용한 인증\n",
    "\n",
    "OpenAI SDK가 *Azure API 키*를 사용하도록 설정하려면 `api_type`을 `azure`로 설정하고 `api_key`를 엔드포인트와 연결된 키로 설정해야 합니다(이 키는 [Azure 포털](https://portal.azure.com)의 *\"리소스 관리\"* 아래 \"키 및 엔드포인트\"*에서 찾을 수 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not use_azure_active_directory:\n",
    "    openai.api_type = 'azure'\n",
    "    openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> 참고: 이 예제에서는 코드에서 변수를 설정하여 Azure API를 사용하도록 라이브러리를 구성했습니다. 개발의 경우 환경 변수를 대신 설정하는 것을 고려하세요:\n",
    "\n",
    "```\n",
    "OPENAI_API_BASE\n",
    "OPENAI_API_KEY\n",
    "OPENAI_API_TYPE\n",
    "OPENAI_API_VERSION\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Microsoft Active Directory를 사용한 인증\n",
    "이제 Microsoft Active Directory 인증을 통해 키를 얻는 방법을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "if use_azure_active_directory:\n",
    "    default_credential = DefaultAzureCredential()\n",
    "    token = default_credential.get_token(\"https://cognitiveservices.azure.com/.default\")\n",
    "\n",
    "    openai.api_type = 'azure_ad'\n",
    "    openai.api_key = token.token"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "토큰은 일정 기간 동안 유효하며 그 이후에는 만료됩니다. 모든 요청에 유효한 토큰이 전송되도록 하려면 요청.auth에 연결하여 만료되는 토큰을 새로 고칠 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "import time\n",
    "import requests\n",
    "\n",
    "if typing.TYPE_CHECKING:\n",
    "    from azure.core.credentials import TokenCredential\n",
    "\n",
    "class TokenRefresh(requests.auth.AuthBase):\n",
    "\n",
    "    def __init__(self, credential: \"TokenCredential\", scopes: typing.List[str]) -> None:\n",
    "        self.credential = credential\n",
    "        self.scopes = scopes\n",
    "        self.cached_token: typing.Optional[str] = None\n",
    "\n",
    "    def __call__(self, req):\n",
    "        if not self.cached_token or self.cached_token.expires_on - time.time() < 300:\n",
    "            self.cached_token = self.credential.get_token(*self.scopes)\n",
    "        req.headers[\"Authorization\"] = f\"Bearer {self.cached_token.token}\"\n",
    "        return req\n",
    "\n",
    "if use_azure_active_directory:\n",
    "    session = requests.Session()\n",
    "    session.auth = TokenRefresh(default_credential, [\"https://cognitiveservices.azure.com/.default\"])\n",
    "\n",
    "    openai.requestssession = session"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "세대 ## 세대\n",
    "\n",
    "설정 및 인증이 완료되면 이제 Azure OpenAI 서비스에서 이미지를 생성하고 반환된 URL에서 이미지를 검색할 수 있습니다."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. 이미지 생성하기\n",
    "\n",
    "이 프로세스의 첫 번째 단계는 실제로 이미지를 생성하는 것입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_response = openai.Image.create(\n",
    "    prompt='A cyberpunk monkey hacker dreaming of a beautiful bunch of bananas, digital art',\n",
    "    size='1024x1024',\n",
    "    n=2\n",
    ")\n",
    "\n",
    "print(generation_response)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image.create` 호출의 응답이 있으면 `requests`를 사용하여 URL에서 다운로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "\n",
    "# First a little setup\n",
    "image_dir = os.path.join(os.curdir, 'images')\n",
    "# If the directory doesn't exist, create it\n",
    "if not os.path.isdir(image_dir):\n",
    "    os.mkdir(image_dir)\n",
    "\n",
    "# With the directory in place, we can initialize the image path (note that filetype should be png)\n",
    "image_path = os.path.join(image_dir, 'generated_image.png')\n",
    "\n",
    "# Now we can retrieve the generated image\n",
    "image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "generated_image = requests.get(image_url).content  # download the image\n",
    "with open(image_path, \"wb\") as image_file:\n",
    "    image_file.write(generated_image)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지를 다운로드한 후 [Pillow](https://pypi.org/project/Pillow/) 라이브러리를 사용하여 이미지를 열고 표시합니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "\n",
    "display(Image.open(image_path))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3a5103089ab7e7c666b279eeded403fcec76de49a40685dbdfe9f9c78ad97c17"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
